{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"emotion extraction using word embeding and LSTM.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOSV3UJrStdwm5/0SFChuXI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"eft3GNhLJXKB"},"source":["from numpy import array\n","from keras.preprocessing.text import one_hot\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers.core import Activation, Dropout, Dense\n","from keras.layers import Flatten, LSTM\n","from keras.layers import GlobalMaxPooling1D\n","from keras.models import Model\n","from keras.layers.embeddings import Embedding\n","from sklearn.model_selection import train_test_split\n","from keras.preprocessing.text import Tokenizer\n","from keras.layers import Input\n","from keras.layers.merge import Concatenate\n","\n","import pandas as pd\n","import numpy as np\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jrIoPgy_KOH_","executionInfo":{"status":"ok","timestamp":1628562513603,"user_tz":420,"elapsed":13670,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"5e9504aa-ed7e-46ac-9c0c-77342ce05bcb"},"source":["pip install hazm"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting hazm\n","  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n","\u001b[K     |████████████████████████████████| 316 kB 4.2 MB/s \n","\u001b[?25hCollecting libwapiti>=0.2.1\n","  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n","\u001b[K     |████████████████████████████████| 233 kB 47.6 MB/s \n","\u001b[?25hCollecting nltk==3.3\n","  Downloading nltk-3.3.0.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 42.3 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n","Building wheels for collected packages: nltk, libwapiti\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394487 sha256=fc27a71ab466a2ebdea3eb63727504cbd416482d20878c89b75b489a145cd1e7\n","  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n","  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154693 sha256=5d03e227023ee00b251f3083fd4c01d54e1e9cb7d41266ca1dcc19c7f996d862\n","  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n","Successfully built nltk libwapiti\n","Installing collected packages: nltk, libwapiti, hazm\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QGXvCptjKTyy","executionInfo":{"status":"ok","timestamp":1628562550483,"user_tz":420,"elapsed":33714,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"b91b3bb7-e7fb-48ba-c8ee-e3ab236c8fe1"},"source":["from __future__ import print_function, unicode_literals\n","import codecs, subprocess, random\n","from collections import Counter\n","from itertools import islice\n","from nltk.tag import untag\n","from sklearn.model_selection import train_test_split\n","from hazm import *\n","from hazm.Chunker import tree2brackets\n","from hazm.PeykareReader import coarse_pos_e as peykare_coarse_pos_e\n","from hazm.DadeganReader import coarse_pos_e as dadegan_coarse_pos_e\n","from google.colab import drive\n","import pandas as pd\n","import numpy as np\n","import pickle\n","import nltk\n","import glob\n","import re\n","import os\n","import io\n","\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"auImIHErKiSK"},"source":["import pandas as pd\n","stop_words = pd.read_json('/content/drive/MyDrive/Colab Notebooks/emotion_project/stopwords-fa.json', encoding= 'utf-8')\n","stopwords=stop_words.transpose()\n","stop_words=stopwords.values.tolist()\n","stopwords[1]='!!'\n","stop_words=stopwords.values.tolist()\n","ss=stopwords.iloc[0,9:798]\n","sss=ss.values.tolist()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWcVZYmmKowF","executionInfo":{"status":"ok","timestamp":1628562578202,"user_tz":420,"elapsed":3627,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"f5f677ac-7c48-40de-8ee6-b72b326e3f2f"},"source":["!pip install emojis\n","import emojis\n","import re\n","import string\n","from string import digits\n","def text_cleaner(text):\n","\n","  # Emoji parsing\n","  text = emojis.decode(str(text))\n","  \n","  # Removing numbers\n","  text = re.sub(r'\\\\d+', '', text)\n","\n","  # Removing single character words\n","  text =  re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n","\n","  # Slang parsing\n","  # for slang, meaning in slangs.items():\n","  #   text = text.replace(slang, meaning)\n","  \n","  text=text.replace(\":\", \"\")\n","  text=text.replace('@', \"\")\n","  text=text.replace(\"#\", \" \")\n","  text=text.replace(\"_\", \" \")\n","  text=text.replace(\"،\", \" \")\n","  text=text.replace(\"\\u200c\", \" \")\n","  text =  re.sub(r\"[a-zA-Z]\", \"\", text)\n","  \n","  # Removing links\n","  text=text.replace(r\"http\\S+\", \"\")\n","  text=text.translate(str.maketrans('', '', string.punctuation))\n","  text=text.translate(str.maketrans('', '', string.digits))\n","  # text = text.translate(None, digits)\n","\n","  # Normalizing Case\n","  # Filter Out Punctuation\n","  # Filter out Stop Words (and Pipeline)\n","\n","  # words = [w for w in text.split() if w.isalpha() and not w in sss]\n","  \n","  words = [w for w in text.split()if not w in sss]\n","  return ' '.join(words)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting emojis\n","  Downloading emojis-0.6.0-py3-none-any.whl (27 kB)\n","Installing collected packages: emojis\n","Successfully installed emojis-0.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQeqhq5VKvYL","executionInfo":{"status":"ok","timestamp":1628562586205,"user_tz":420,"elapsed":4470,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"88eae834-8963-473a-8664-5a8cc07ed1c5"},"source":["#clean data adn stemming\n","import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/emotion_project/Emotion.csv', encoding= 'utf-8')\n","df.loc[0,'text']\n","clean_text=[]\n","stemmer = Stemmer()\n","for i in range(len(df)) :\n","  text=text_cleaner(df.loc[i,'text'])\n","  # text=df.loc[i,'text']\n","  wr=[stemmer.stem(w) for w in text.split()]\n","  t=' '.join(wr)\n","  clean_text.append(t)\n","# clean_text[0]\n","len(clean_text)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5999"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Dg0LKBsK1Ct","executionInfo":{"status":"ok","timestamp":1628562590724,"user_tz":420,"elapsed":1104,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"c7600ef1-0283-4e85-d628-b355e70e5d7b"},"source":["df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/emotion_project/EmotionTest.csv', encoding= 'utf-8')\n","clean_text_test=[]\n","stemmer = Stemmer()\n","for i in range(len(df_test)) :\n","  text=text_cleaner(df_test.loc[i,'text'])\n","  # text=df.loc[i,'text']\n","  wr=[stemmer.stem(w) for w in text.split()]\n","  t=' '.join(wr)\n","  clean_text_test.append(t)\n","len(clean_text_test)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"wnEDJKmDLGky"},"source":["y=df.loc[:,'label']\n","y.replace('\\n','')\n","y=y.values.tolist()\n","# x=df_featurs.values.tolist()\n","for i in range(len(y)):\n","  y[i]=y[i].replace('\\n','')\n","  y[i]=y[i].replace('.','')\n","label=[]\n","for i in range(len(y)):\n","  yy = [int(t) for t in y[i].split(' ')]\n","  label.append(yy)\n","label=np.array(label)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WMse1FPiLCAx"},"source":["\n","y_test=df_test.loc[:,'label']\n","y_test.replace('\\n','')\n","y_test=y_test.values.tolist()\n","# x_test=df_featurs2.values.tolist()\n","for i in range(len(y_test)):\n","  y_test[i]=y_test[i].replace('\\n','')\n","  y_test[i]=y_test[i].replace('.','')\n","\n","ytest=[]\n","for i in range(len(y_test)):\n","  yy = [int(t) for t in y_test[i].split(' ')]\n","  ytest.append(yy)\n","ytest=np.array(ytest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ff6YH81jLNkb"},"source":["tokenizer = Tokenizer(num_words=2000)\n","tokenizer.fit_on_texts(clean_text)\n","\n","X_train = tokenizer.texts_to_sequences(clean_text)\n","X_test = tokenizer.texts_to_sequences(clean_text_test)\n","\n","vocab_size = len(tokenizer.word_index) + 1\n","\n","maxlen = 200\n","\n","X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n","X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hGIK2xcaPeQy"},"source":["from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","\n","embeddings_dictionary = dict()\n","\n","glove_file = open('/content/drive/MyDrive/Colab Notebooks/emotion_project/vocab_embed.txt', encoding=\"utf8\")\n","\n","for line in glove_file:\n","    records = line.split()\n","    word = records[0]\n","    vector_dimensions = asarray(records[1:], dtype='float32')\n","    embeddings_dictionary[word] = vector_dimensions\n","glove_file.close()\n","\n","embedding_matrix = zeros((vocab_size, 100))\n","for word, index in tokenizer.word_index.items():\n","    embedding_vector = embeddings_dictionary.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix[index] = embedding_vector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BCDid0g-QC6j","executionInfo":{"status":"ok","timestamp":1628563004820,"user_tz":420,"elapsed":281819,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"d70a6891-d770-4b57-cc30-8f53a391e5a4"},"source":["deep_inputs = Input(shape=(maxlen,))\n","embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n","LSTM_Layer_1 = LSTM(128)(embedding_layer)\n","dense_layer_1 = Dense(10, activation='sigmoid')(LSTM_Layer_1)\n","model = Model(inputs=deep_inputs, outputs=dense_layer_1)\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","print(model.summary())\n","history = model.fit(X_train, label, batch_size=128, epochs=10, verbose=1, validation_split=0.2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, 200)]             0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, 200, 100)          1757700   \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               117248    \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                1290      \n","=================================================================\n","Total params: 1,876,238\n","Trainable params: 118,538\n","Non-trainable params: 1,757,700\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","38/38 [==============================] - 43s 662ms/step - loss: 0.5413 - acc: 0.1568 - val_loss: 0.3346 - val_acc: 0.1550\n","Epoch 2/10\n","38/38 [==============================] - 24s 643ms/step - loss: 0.3319 - acc: 0.1751 - val_loss: 0.3353 - val_acc: 0.1708\n","Epoch 3/10\n","38/38 [==============================] - 24s 644ms/step - loss: 0.3320 - acc: 0.1547 - val_loss: 0.3353 - val_acc: 0.1550\n","Epoch 4/10\n","38/38 [==============================] - 25s 651ms/step - loss: 0.3344 - acc: 0.1462 - val_loss: 0.3360 - val_acc: 0.1708\n","Epoch 5/10\n","38/38 [==============================] - 25s 657ms/step - loss: 0.3348 - acc: 0.1740 - val_loss: 0.3354 - val_acc: 0.1708\n","Epoch 6/10\n","38/38 [==============================] - 25s 653ms/step - loss: 0.3319 - acc: 0.1568 - val_loss: 0.3359 - val_acc: 0.1708\n","Epoch 7/10\n","38/38 [==============================] - 25s 657ms/step - loss: 0.3331 - acc: 0.1812 - val_loss: 0.3364 - val_acc: 0.1550\n","Epoch 8/10\n","38/38 [==============================] - 25s 654ms/step - loss: 0.3334 - acc: 0.1603 - val_loss: 0.3349 - val_acc: 0.1550\n","Epoch 9/10\n","38/38 [==============================] - 25s 653ms/step - loss: 0.3310 - acc: 0.1450 - val_loss: 0.3357 - val_acc: 0.1550\n","Epoch 10/10\n","38/38 [==============================] - 25s 648ms/step - loss: 0.3329 - acc: 0.1614 - val_loss: 0.3360 - val_acc: 0.1708\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Us93C7riRbM-","executionInfo":{"status":"ok","timestamp":1628563047707,"user_tz":420,"elapsed":2785,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"adb2886a-85de-4cbe-b2a8-27c2eb8a7dc1"},"source":["score = model.evaluate(X_test, ytest, verbose=1)\n","\n","print(\"Test Score:\", score[0])\n","print(\"Test Accuracy:\", score[1])\n","len(X_test)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["32/32 [==============================] - 2s 61ms/step - loss: 0.3347 - acc: 0.1180\n","Test Score: 0.3347246050834656\n","Test Accuracy: 0.11800000071525574\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"O_oEuvpS7Dd5"},"source":["\n","yhat=model.predict(X_test)\n","for i in range(len(yhat)):\n","  for j in range(10):\n","    if yhat[i][j] <0.5 :\n","      yhat[i][j]=0\n","    else:\n","      yhat[i][j]=1\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SP4cmj7N7UVX","executionInfo":{"status":"ok","timestamp":1628563463037,"user_tz":420,"elapsed":467,"user":{"displayName":"zahra fathollahi","photoUrl":"","userId":"00807975073601722929"}},"outputId":"f086a30d-8d73-45e5-d918-98ade8e1c1bb"},"source":["from sklearn.metrics import hamming_loss, accuracy_score\n","print(hamming_loss(ytest, yhat))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.1226\n"],"name":"stdout"}]}]}